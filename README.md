### Multi-lib-Web-Scraping-BS-Requests-Selenium-Scrapy-Regex

This repository is a **comprehensive web scraping project** that leverages multiple Python libraries, including **BeautifulSoup, Requests, Selenium, Scrapy, and Regex**, to extract and process data from websites. The purpose of this project is to demonstrate a variety of web scraping techniques, ranging from simple HTTP requests to advanced browser automation and framework usage.

---

### üöÄ **Project Overview**:
The repository contains various Python scripts, each showcasing specific use cases and challenges of web scraping. Key topics covered include:  

- **Requests & BeautifulSoup**: Scraping static websites with HTTP requests and parsing HTML content.
- **Regex**: Extracting specific patterns from text data.
- **Selenium**: Automating browser interactions, handling dynamic content, and scrolling through pages.
- **Scrapy Framework**: Advanced web scraping using spiders and project-based approaches.

---

### üìÇ **Contents**:
Here are the primary files and their functionalities:

1. **Requests & BeautifulSoup Scripts**:
   - `1_request.py`: Demonstrates basic requests for fetching web content.
   - `2_1_BeautifulSoup.py`: Parsing HTML with BeautifulSoup.
   - `2_2_1_BeautifulSoup_skysports.py` & `2_2_2_BeautifulSoup_skysports.py`: Extracting sports data from websites.

2. **Regex Usage**:
   - `4_Regex.py`: Extracting and cleaning specific patterns from text.

3. **Selenium Examples**:
   - `6_Selenium_start.py`: Introduction to Selenium for web scraping.
   - `7_1_1_Locators_in_Selenium_GoogleBy_Xpath_CSSselector.py`: Demonstrates advanced locators in Selenium.
   - `8_Waiting_types_Implicit_Explicite_Eaits.py`: Handling waits in Selenium.
   - `10_Scroll_in_Site_and_Extract_Image_and_Data_Export_Selenium.py`: Automating scrolling and extracting data.

4. **Instagram Automation**:
   - `12_Instagram_Robat_part1.py` & `13-Instagram_Robat_part2.py`: Creating an Instagram bot for automated actions.

5. **Scrapy Framework**:
   - `14_Scrapy_Framework_Installation_Guide.py`: Installation guide for Scrapy.
   - `15_Scrapy_eagle.py`: An example spider for advanced scraping.
   - `16_Scrapy_Filmnet_Filimo_Download_Film.py`: Extracting movie details using Scrapy.

---

### üìã **Setup Instructions**:
1. Clone the repository:
   ```bash
   git clone https://github.com/M-RezaeiGH/Multi-lib-Web-Scraping-BS-Requests-Selenium-Scrapy-Regex.git
   ```
2. Install required dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the scripts with:
   ```bash
   python <script_name>.py
   ```

---

### üõ†Ô∏è **Key Features**:
- **Multi-Library Approach**: Combines the strengths of various libraries to handle diverse scraping challenges.
- **Dynamic and Static Scraping**: Covers both static websites and dynamic pages that require JavaScript rendering.
- **Exporting Data**: Save scraped data in JSON, CSV, and other formats.
- **Automation**: Includes examples of browser automation and handling user interactions.

---

### üìú **License**:
This project is licensed under the **Apache License 2.0**. See the [LICENSE](LICENSE) file for details.

---

Feel free to explore, contribute, or fork this repository to adapt it to your web scraping projects!
